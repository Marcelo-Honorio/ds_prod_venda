{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa6988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from datetime import timedelta\n",
    "import os\n",
    "from pathlib import Path\n",
    "#from lightgbm import LGBMRegressor\n",
    "from mlforecast import MLForecast\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from window_ops.rolling import rolling_mean\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ac1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir o diretório\n",
    "os.chdir(os.getcwd()[:-9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d43d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar dataset\n",
    "df = pd.read_parquet(\"data/processed/vendas_engineered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b47990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147414 entries, 0 to 147413\n",
      "Data columns (total 29 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   cfop           147414 non-null  int64         \n",
      " 1   nnf            147414 non-null  int64         \n",
      " 2   codfil         147414 non-null  int64         \n",
      " 3   xnomeemit      147414 non-null  object        \n",
      " 4   xfantemit      147414 non-null  object        \n",
      " 5   cnpjdest       147414 non-null  int64         \n",
      " 6   xmun           147414 non-null  object        \n",
      " 7   cod            147414 non-null  float64       \n",
      " 8   seqprod        147414 non-null  int64         \n",
      " 9   xprod          147414 non-null  object        \n",
      " 10  tipo           147414 non-null  object        \n",
      " 11  qcom           147414 non-null  float64       \n",
      " 12  ucom           147414 non-null  object        \n",
      " 13  ano            147414 non-null  int64         \n",
      " 14  mes            147414 non-null  int64         \n",
      " 15  nome_correto   147414 non-null  object        \n",
      " 16  cod_ibge       147414 non-null  object        \n",
      " 17  nome_oficial   147414 non-null  object        \n",
      " 18  uf_oficial     147414 non-null  object        \n",
      " 19  data           147414 non-null  datetime64[ns]\n",
      " 20  VlCusteio      147174 non-null  float64       \n",
      " 21  AreCusteio     147174 non-null  float64       \n",
      " 22  preco_feijao   124544 non-null  float64       \n",
      " 23  preco_laranja  124544 non-null  float64       \n",
      " 24  preco_trigo    124544 non-null  float64       \n",
      " 25  preco_soja     147414 non-null  float64       \n",
      " 26  preco_milho    147414 non-null  float64       \n",
      " 27  cluster        147414 non-null  int32         \n",
      " 28  sample_weight  147414 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(10), int32(1), int64(7), object(10)\n",
      "memory usage: 32.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fe2349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-20>:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "<positron-console-cell-20>:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por produto e data\n",
    "df = df.sort_values([\"cluster\", \"data\"])\n",
    "\n",
    "# Separar treino/teste\n",
    "dias_teste = 6\n",
    "train = (\n",
    "    df.groupby(\"cluster\", group_keys=False)\n",
    "      .apply(lambda x: x.iloc[:-7])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "test = (\n",
    "    df.groupby(\"cluster\", group_keys=False)\n",
    "      .apply(lambda x: x.iloc[-7:])\n",
    "      .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d98c33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo com MLForecast e avaliação com erro médio ponderado\n",
    "def erro_ponderado_por_qtd(df_aval, col_pred):\n",
    "    erros = []\n",
    "    for uid, grupo in df_aval.groupby(\"cluster\"):\n",
    "        if len(grupo) < 1:\n",
    "            continue\n",
    "        erro = root_mean_squared_error(grupo[\"qcom\"], grupo[col_pred])\n",
    "        peso = len(grupo)\n",
    "        erros.append((erro, peso))\n",
    "\n",
    "    total_pesos = sum(p for _, p in erros)\n",
    "    if total_pesos == 0:\n",
    "        return np.nan\n",
    "\n",
    "    erro_ponderado = sum(e * p for e, p in erros) / total_pesos\n",
    "    return erro_ponderado\n",
    "\n",
    "def rodar_mlforecast(df_train, df_test):\n",
    "    models = [\n",
    "        #LGBMRegressor(\n",
    "        #    random_state=42,\n",
    "        #    verbosity=-1,\n",
    "        #    min_child_samples=30,  # Maior valor para evitar overfitting\n",
    "        #    reg_alpha=0.2,        # Regularização L1\n",
    "        #    reg_lambda=0.2,       # Regularização L2\n",
    "        #    n_estimators=100\n",
    "        #),\n",
    "        HistGradientBoostingRegressor(\n",
    "            random_state=42,\n",
    "            min_samples_leaf=30,\n",
    "            l2_regularization=0.2,\n",
    "            max_iter=100\n",
    "        ),\n",
    "        RandomForestRegressor(\n",
    "            random_state=42,\n",
    "            n_estimators = 100\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    fcst = MLForecast(\n",
    "        models=models,\n",
    "        freq='M',\n",
    "        lags=[1, 7, 14],\n",
    "        lag_transforms={\n",
    "            1: [ExpandingMean()],\n",
    "            3: [RollingMean(window_size=3)],\n",
    "            7: [RollingMean(window_size=7)],\n",
    "            14: [RollingMean(window_size=14)]\n",
    "        },\n",
    "        date_features=[\"mes\", \"ano\"]\n",
    "    )\n",
    "\n",
    "    fcst.fit(df_train, \n",
    "             id_col=\"cluster\", \n",
    "             time_col=\"data\", \n",
    "             target_col=\"qcom\", \n",
    "             dropna=False,\n",
    "             weight_col=\"sample_weight\",\n",
    "             static_features=[]\n",
    "             )\n",
    "    pred = fcst.predict(7)\n",
    "\n",
    "    df_aval = df_test[[\"cluster\", \"data\", \"qcom\"]].merge(pred, on=[\"cluster\", \"data\"], how=\"inner\")\n",
    "    resultados = []\n",
    "    best_mape = 1\n",
    "    for col in pred.columns:\n",
    "        if col.startswith(\"LGBM\") or col.startswith(\"Hist\") or col.startswith(\"Rand\"):\n",
    "            mae = mean_absolute_error(df_aval[\"qcom\"], df_aval[col])\n",
    "            mape = mean_absolute_percentage_error(df_aval[\"qcom\"], df_aval[col])\n",
    "            erro_pond = erro_ponderado_por_qtd(df_aval, col)\n",
    "            resultados.append((col, mae, mape, erro_pond))\n",
    "            print(f\"{col}:\\n MAE: {mae:.2f}\\n MAPE: {mape:.2%}\\n Erro Ponderado: {erro_pond:.2f}\\n\")\n",
    "\n",
    "            if mape < best_mape:\n",
    "                modelo = col\n",
    "                best_mape = mape\n",
    "\n",
    "    best_model = {modelo: best_mape}\n",
    "\n",
    "    return pred, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05947d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar\n",
    "predicoes, best_model = rodar_mlforecast(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo com MLForecast e avaliação com erro médio ponderado\n",
    "def erro_ponderado_por_qtd(df_aval, col_pred):\n",
    "    erros = []\n",
    "    for uid, grupo in df_aval.groupby(\"unique_id\"):\n",
    "        if len(grupo) < 1:\n",
    "            continue\n",
    "        erro = root_mean_squared_error(grupo[\"y\"], grupo[col_pred])\n",
    "        peso = len(grupo)\n",
    "        erros.append((erro, peso))\n",
    "\n",
    "    total_pesos = sum(p for _, p in erros)\n",
    "    if total_pesos == 0:\n",
    "        return np.nan\n",
    "\n",
    "    erro_ponderado = sum(e * p for e, p in erros) / total_pesos\n",
    "    return erro_ponderado\n",
    "\n",
    "def is_weekend(dates):\n",
    "    \"\"\"É final de semana\"\"\"\n",
    "    return dates.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "def day_month(dates):\n",
    "    \"\"\"dia do mês\"\"\"\n",
    "    return dates.day\n",
    "\n",
    "def month(dates):\n",
    "    \"\"\"mes do ano\"\"\"\n",
    "    return dates.month\n",
    "\n",
    "def rodar_mlforecast(df_train, df_test, save_path='melhores_modelos'):\n",
    "    # Criar diretório para salvar os modelos se não existir\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    models = [\n",
    "        ('LGBM', LGBMRegressor(\n",
    "            random_state=42,\n",
    "            verbosity=-1,\n",
    "            min_child_samples=30,\n",
    "            reg_alpha=0.2,\n",
    "            reg_lambda=0.2,\n",
    "            n_estimators=100\n",
    "        )),\n",
    "        ('HGBR', HistGradientBoostingRegressor(\n",
    "            random_state=42,\n",
    "            min_samples_leaf=30,\n",
    "            l2_regularization=0.2,\n",
    "            max_iter=100\n",
    "        )),\n",
    "        ('RF', RandomForestRegressor(\n",
    "            random_state=42,\n",
    "            n_estimators=100\n",
    "        ))\n",
    "    ]\n",
    "\n",
    "    # Criar dicionário para mapear nomes de colunas para modelos\n",
    "    model_map = {\n",
    "        'LGBMRegressor': models[0][1],\n",
    "        'HistGradientBoostingRegressor': models[1][1],\n",
    "        'RandomForestRegressor': models[2][1]\n",
    "    }\n",
    "\n",
    "    fcst = MLForecast(\n",
    "        models=[m[1] for m in models],\n",
    "        freq='D',\n",
    "        lags=[1, 3, 7],\n",
    "        lag_transforms={\n",
    "            1: [ExpandingMean()],\n",
    "            3: [RollingMean(window_size=3)],\n",
    "            7: [RollingMean(window_size=7)],\n",
    "            14: [RollingMean(window_size=14)]\n",
    "        },\n",
    "        date_features=[\"dayofweek\", \"dayofyear\", is_weekend, day_month, month]\n",
    "    )\n",
    "\n",
    "    fcst.fit(df_train, \n",
    "             id_col=\"unique_id\", \n",
    "             time_col=\"ds\", \n",
    "             target_col=\"y\", \n",
    "             dropna=False,\n",
    "             weight_col=\"sample_weight\",\n",
    "             static_features=[\"product_cluster\"]\n",
    "             )\n",
    "    \n",
    "    # Fazer previsões\n",
    "    pred = fcst.predict(7)\n",
    "\n",
    "    # Avaliar modelos\n",
    "    df_aval = df_test[[\"unique_id\", \"ds\", \"y\"]].merge(pred, on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "    resultados = []\n",
    "    best_metrics = {\n",
    "        'model_name': None,\n",
    "        'model': None,\n",
    "        'mae': float('inf'),\n",
    "        'mape': float('inf'),\n",
    "        'erro_ponderado': float('inf')\n",
    "    }\n",
    "\n",
    "    for col in pred.columns:\n",
    "        if any(col.startswith(m[0]) for m in models):\n",
    "            mae = mean_absolute_error(df_aval[\"y\"], df_aval[col])\n",
    "            mape = mean_absolute_percentage_error(df_aval[\"y\"], df_aval[col])\n",
    "            erro_pond = erro_ponderado_por_qtd(df_aval, col)\n",
    "            \n",
    "            resultados.append({\n",
    "                'model_name': col,\n",
    "                'mae': mae,\n",
    "                'mape': mape,\n",
    "                'erro_ponderado': erro_pond\n",
    "            })\n",
    "            \n",
    "            print(f\"{col}:\\n MAE: {mae:.2f}\\n MAPE: {mape:.2%}\\n Erro Ponderado: {erro_pond:.2f}\\n\")\n",
    "\n",
    "            # Atualizar melhor modelo se encontrar um MAPE menor\n",
    "            if mape < best_metrics['mape']:\n",
    "                best_metrics.update({\n",
    "                    'model_name': col,\n",
    "                    'model': model_map[col],\n",
    "                    'mae': mae,\n",
    "                    'mape': mape,\n",
    "                    'erro_ponderado': erro_pond\n",
    "                })\n",
    "\n",
    "    # Salvar o melhor modelo\n",
    "    if best_metrics['model_name']:\n",
    "        model_info = {\n",
    "            'model': best_metrics['model'],\n",
    "            'model_name': best_metrics['model_name'],\n",
    "            'metrics': {\n",
    "                'mae': best_metrics['mae'],\n",
    "                'mape': best_metrics['mape'],\n",
    "                'erro_ponderado': best_metrics['erro_ponderado']\n",
    "            },\n",
    "            'mlforecast_config': {\n",
    "                'freq': 'D',\n",
    "                'lags': [1, 3, 7],\n",
    "                'lag_transforms': {\n",
    "                    1: [ExpandingMean()],\n",
    "                    3: [RollingMean(window_size=3)],\n",
    "                    7: [RollingMean(window_size=7)],\n",
    "                    14: [RollingMean(window_size=14)]\n",
    "                },\n",
    "                'date_features': [\"dayofweek\", \"dayofyear\", is_weekend, day_month, month]\n",
    "            },\n",
    "            'fit_params': {\n",
    "                'id_col': \"unique_id\",\n",
    "                'time_col': \"ds\", \n",
    "                'target_col': \"y\",\n",
    "                'static_features': [\"product_cluster\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Salvar o objeto do modelo\n",
    "        model_path = f\"{save_path}/{best_metrics['model_name']}_best_model.pkl\"\n",
    "        joblib.dump(model_info, model_path)\n",
    "        print(f\"\\nMelhor modelo salvo em: {model_path}\")\n",
    "        print(f\"Modelo: {best_metrics['model_name']} com MAPE: {best_metrics['mape']:.2%}\")\n",
    "\n",
    "    return pred, resultados, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9446dace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor:\n",
      " MAE: 6.29\n",
      " MAPE: 27.16%\n",
      " Erro Ponderado: 7.66\n",
      "\n",
      "\n",
      "Melhor modelo salvo em: melhores_modelos/LGBMRegressor_best_model.pkl\n",
      "Modelo: LGBMRegressor com MAPE: 27.16%\n"
     ]
    }
   ],
   "source": [
    "# Treinar e avaliar modelos\n",
    "previsoes, resultados, melhor_modelo = rodar_mlforecast(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83a4d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Funções auxiliares\n",
    "# ----------------------------\n",
    "def erro_ponderado_por_qtd(df_aval, col_pred):\n",
    "    erros = []\n",
    "    for uid, grupo in df_aval.groupby(\"unique_id\"):\n",
    "        if len(grupo) < 1:\n",
    "            continue\n",
    "        erro = root_mean_squared_error(grupo[\"y\"], grupo[col_pred])\n",
    "        peso = len(grupo)\n",
    "        erros.append((erro, peso))\n",
    "\n",
    "    total_pesos = sum(p for _, p in erros)\n",
    "    if total_pesos == 0:\n",
    "        return np.nan\n",
    "\n",
    "    erro_ponderado = sum(e * p for e, p in erros) / total_pesos\n",
    "    return erro_ponderado\n",
    "\n",
    "def is_weekend(dates):\n",
    "    return pd.Series(dates).dt.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "def day_month(dates):\n",
    "    return pd.Series(dates).dt.day\n",
    "\n",
    "def month(dates):\n",
    "    return pd.Series(dates).dt.month\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Estratégia para produtos\n",
    "# ----------------------------\n",
    "\n",
    "def split_por_volume(df, limiar_curto=12, limiar_medio=30):\n",
    "    contagens = df['unique_id'].value_counts()\n",
    "    ids_curto = contagens[contagens < limiar_curto].index\n",
    "    ids_medio = contagens[(contagens >= limiar_curto) & (contagens < limiar_medio)].index\n",
    "    ids_longo = contagens[contagens >= limiar_medio].index\n",
    "\n",
    "    return ids_curto, ids_medio, ids_longo\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Média móvel simples para séries curtas\n",
    "# ----------------------------\n",
    "\n",
    "def media_movel_simples(df, janela=3, dias_prever=7):\n",
    "    resultados = []\n",
    "\n",
    "    for uid, grupo in df.groupby(\"unique_id\"):\n",
    "        grupo = grupo.sort_values(\"ds\")\n",
    "        media = grupo[\"y\"].tail(janela).mean()\n",
    "        datas_futuras = pd.date_range(grupo[\"ds\"].max() + pd.Timedelta(days=1), periods=dias_prever)\n",
    "        preds = pd.DataFrame({\n",
    "            \"unique_id\": uid,\n",
    "            \"ds\": datas_futuras,\n",
    "            \"y_pred\": media\n",
    "        })\n",
    "        resultados.append(preds)\n",
    "\n",
    "    return pd.concat(resultados, ignore_index=True)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Forecast com MLForecast\n",
    "# ----------------------------\n",
    "\n",
    "def rodar_mlforecast(df_train, df_test):\n",
    "    models = [\n",
    "        LGBMRegressor(\n",
    "            random_state=42,\n",
    "            verbosity=-1,\n",
    "            min_child_samples=30,\n",
    "            reg_alpha=0.2,\n",
    "            reg_lambda=0.2,\n",
    "            n_estimators=100\n",
    "        ),\n",
    "        HistGradientBoostingRegressor(\n",
    "            random_state=42,\n",
    "            min_samples_leaf=30,\n",
    "            l2_regularization=0.2,\n",
    "            max_iter=100\n",
    "        ),\n",
    "        RandomForestRegressor(\n",
    "            random_state=42,\n",
    "            n_estimators=100\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    fcst = MLForecast(\n",
    "        models=models,\n",
    "        freq='D',\n",
    "        lags=[1, 3, 7, 14],\n",
    "        lag_transforms={\n",
    "            1: [ExpandingMean()],\n",
    "            3: [RollingMean(window_size=3)],\n",
    "            7: [RollingMean(window_size=7)],\n",
    "            14: [RollingMean(window_size=14)]\n",
    "        },\n",
    "        date_features=[\"dayofweek\", \"dayofyear\", is_weekend, day_month, month]\n",
    "    )\n",
    "\n",
    "    fcst.fit(\n",
    "        df_train,\n",
    "        id_col=\"unique_id\",\n",
    "        time_col=\"ds\",\n",
    "        target_col=\"y\",\n",
    "        dropna=False,\n",
    "        weight_col=\"sample_weight\" if \"sample_weight\" in df_train.columns else None,\n",
    "        static_features=[\"product_cluster\"] if \"product_cluster\" in df_train.columns else None\n",
    "    )\n",
    "\n",
    "    pred = fcst.predict(7)\n",
    "\n",
    "    df_aval = df_test[[\"unique_id\", \"ds\", \"y\"]].merge(pred, on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "    resultados = []\n",
    "    best_mape = 1\n",
    "    modelo = None\n",
    "\n",
    "    for col in pred.columns:\n",
    "        if col.startswith((\"LGBM\", \"Hist\", \"Rand\")):\n",
    "            mae = mean_absolute_error(df_aval[\"y\"], df_aval[col])\n",
    "            mape = mean_absolute_percentage_error(df_aval[\"y\"], df_aval[col])\n",
    "            erro_pond = erro_ponderado_por_qtd(df_aval, col)\n",
    "            resultados.append((col, mae, mape, erro_pond))\n",
    "            print(f\"{col}:\\n MAE: {mae:.2f} | MAPE: {mape:.2%} | Erro Ponderado: {erro_pond:.2f}\")\n",
    "\n",
    "            if mape < best_mape:\n",
    "                modelo = col\n",
    "                best_mape = mape\n",
    "\n",
    "    best_model = {modelo: best_mape}\n",
    "    return pred, best_model\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Estratégia com divisão por volume de dados\n",
    "# ----------------------------\n",
    "\n",
    "def pipeline_previsao(df, dias_prever=7):\n",
    "    ids_curto, ids_medio, ids_longo = split_por_volume(df)\n",
    "\n",
    "    df_curto = df[df['unique_id'].isin(ids_curto)]\n",
    "    df_medio_longo = df[df['unique_id'].isin(ids_medio.union(ids_longo))]\n",
    "\n",
    "    print(f\"🔹 Produtos com poucos dados: {len(ids_curto)}\")\n",
    "    print(f\"🔹 Produtos com dados suficientes: {len(ids_medio.union(ids_longo))}\")\n",
    "\n",
    "    # Previsão por média móvel\n",
    "    pred_curto = media_movel_simples(df_curto, dias_prever=dias_prever)\n",
    "\n",
    "    # Previsão por MLForecast para os demais\n",
    "    df_train = df_medio_longo.groupby(\"unique_id\", group_keys=False).apply(\n",
    "        lambda g: g.sort_values(\"ds\").iloc[:-dias_prever] if len(g) > dias_prever else g\n",
    "    ).reset_index(drop=True)\n",
    "    df_test = df_medio_longo[~df_medio_longo.index.isin(df_train.index)]\n",
    "\n",
    "    pred_ml, best_model = rodar_mlforecast(df_train, df_test)\n",
    "    pred_ml.rename(columns={list(best_model.keys())[0]: \"y_pred\"}, inplace=True)\n",
    "\n",
    "    # Combina as previsões\n",
    "    previsoes = pd.concat([pred_curto, pred_ml[[\"unique_id\", \"ds\", \"y_pred\"]]], ignore_index=True)\n",
    "\n",
    "    # Calcular erro global\n",
    "    df_real = df[df[\"ds\"].isin(previsoes[\"ds\"].unique())]\n",
    "    df_merge = df_real.merge(previsoes, on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "    erro_segmentado = calcular_erro_total(df_merge)\n",
    "\n",
    "    return previsoes.sort_values([\"unique_id\", \"ds\"]), erro_segmentado\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Estratégia: aplicar MLForecast para todos\n",
    "# ----------------------------\n",
    "\n",
    "def previsao_todos_mlforecast(df, dias_prever=7):\n",
    "    df = df.sort_values([\"unique_id\", \"ds\"])\n",
    "    \n",
    "    df_train = df.groupby(\"unique_id\", group_keys=False).apply(\n",
    "        lambda g: g.iloc[:-dias_prever] if len(g) > dias_prever else g\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    df_test = df[~df.index.isin(df_train.index)]\n",
    "\n",
    "    pred, best_model = rodar_mlforecast(df_train, df_test)\n",
    "    pred.rename(columns={list(best_model.keys())[0]: \"y_pred\"}, inplace=True)\n",
    "\n",
    "    df_merge = df_test.merge(pred[[\"unique_id\", \"ds\", \"y_pred\"]], on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "    erro_total = calcular_erro_total(df_merge)\n",
    "\n",
    "    return df_merge.sort_values([\"unique_id\", \"ds\"]), erro_total\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Execução e Comparação Final\n",
    "# ----------------------------\n",
    "\n",
    "def comparar_estrategias(df):\n",
    "    print(\"\\n🔍 Rodando estratégia segmentada por volume de histórico...\")\n",
    "    previsoes_segmentado, erro_segmentado = pipeline_previsao(df)\n",
    "    print(f\"\\n📊 Erro ponderado - Estratégia segmentada: {erro_segmentado:.2f}\")\n",
    "\n",
    "    print(\"\\n🔍 Rodando estratégia com MLForecast para todos...\")\n",
    "    previsoes_ml, erro_ml = previsao_todos_mlforecast(df)\n",
    "    print(f\"📊 Erro ponderado - MLForecast para todos: {erro_ml:.2f}\")\n",
    "\n",
    "    print(\"\\n📈 Resultado final:\")\n",
    "    if erro_segmentado < erro_ml:\n",
    "        print(\"✅ Melhor usar abordagem segmentada por volume de histórico.\")\n",
    "    else:\n",
    "        print(\"✅ Melhor aplicar MLForecast para todos os produtos.\")\n",
    "\n",
    "    return previsoes_segmentado, previsoes_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71863d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Rodando estratégia segmentada por volume de histórico...\n",
      "🔹 Produtos com poucos dados: 2822\n",
      "🔹 Produtos com dados suficientes: 2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marce\\AppData\\Local\\Temp\\ipykernel_22032\\547070314.py:163: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_train = df_medio_longo.groupby(\"unique_id\", group_keys=False).apply(\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor:\n",
      " MAE: 6.19 | MAPE: 27.09% | Erro Ponderado: 7.47\n",
      "HistGradientBoostingRegressor:\n",
      " MAE: 6.23 | MAPE: 29.35% | Erro Ponderado: 7.45\n",
      "RandomForestRegressor:\n",
      " MAE: 6.11 | MAPE: 28.26% | Erro Ponderado: 7.35\n",
      "\n",
      "📊 Erro ponderado - Estratégia segmentada: 7.84\n",
      "\n",
      "🔍 Rodando estratégia com MLForecast para todos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marce\\AppData\\Local\\Temp\\ipykernel_22032\\547070314.py:189: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_train = df.groupby(\"unique_id\", group_keys=False).apply(\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag3, lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag3_window_size3, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag7, lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\marce\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag14, expanding_mean_lag1, rolling_mean_lag7_window_size7, rolling_mean_lag14_window_size14.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor:\n",
      " MAE: 5.50 | MAPE: 26.49% | Erro Ponderado: 6.60\n",
      "HistGradientBoostingRegressor:\n",
      " MAE: 5.52 | MAPE: 27.48% | Erro Ponderado: 6.56\n",
      "RandomForestRegressor:\n",
      " MAE: 5.83 | MAPE: 28.48% | Erro Ponderado: 6.98\n",
      "📊 Erro ponderado - MLForecast para todos: 6.60\n",
      "\n",
      "📈 Resultado final:\n",
      "✅ Melhor aplicar MLForecast para todos os produtos.\n"
     ]
    }
   ],
   "source": [
    "previsoes_segmentado, previsoes_ml = comparar_estrategias(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
